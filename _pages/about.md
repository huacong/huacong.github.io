---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

# About Me

<span class='anchor' id='about-me'></span>

Hi! I'm Cong Hua (åèª, E-mail: huacong23z@ict.ac.cn). Now I am a PhD. student of **Institute of Computing Technology, Chinese Academy of Sciences (ICT, CAS)**, supervised by Prof. [Qingming Huang](https://qmhuang-ucas.github.io/) (IEEE Fellow) and [Qianqian Xu](https://qianqianxu010.github.io/) (Professor at ICT, CAS). I have received the B.E. degree in computer science and technology from [Jilin University](https://www.jlu.edu.cn/), advised by [Yu Jiang](https://ccst.jlu.edu.cn/info/1028/19116.htm) and [Yue Gao](https://www.gaoyue.org/). My research interests include machine learning and multi-modal learning. I have authored or co-authored several academic papers in top-tier international conferences and journals, including ICML and TNNLS. If you are interested in my research, please email me at <a href="huacong23z@ict.ac.cn">huacong23z@ict.ac.cn</a>.


<!-- I am also lucky to have opportunities to collaborate with [Zhiyong Yang (æ¨æ™ºå‹‡)](https://joshuaas.github.io/) (Assistant Professor at UCAS) and [Yangbangyan Jiang (å§œé˜³é‚¦å½¦)](https://jiangyangby.github.io/) (Postdoc at UCAS). -->

<!-- # ğŸ”¥ News
- *2022.11*: &nbsp;ğŸ‰ğŸ‰ I have obtained the National Scholarship (å›½å®¶å¥–å­¦é‡‘) from the Ministry of Education of the Peopleâ€™s Republic of China.
- *2022.09*: &nbsp;ğŸ‰ğŸ‰ Two of our papers have been accepted by NeurIPS 2022 (One paper has been selected as an oral presentation and one is a poster). 
- *2022.06*: &nbsp;ğŸ‰ğŸ‰ Our XCurve-v1.0.0 library has been released! Please Try now and give us feedback! -->

# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2024</div><img src='images/ReconBoost.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**<font size=4>ReconBoost: Boosting Can Achieve Modality Reconcilement</font>**

**Cong Hua**, Qianqian Xu<sup>\*</sup>, Shilong Bao, Zhiyong Yang, Qingming Huang<sup>\*</sup>

International Conference on Machine Learning (**ICML**) 2024

[\[Paper\]](https://arxiv.org/pdf/2405.09321) \|[\[Code\]](https://github.com/huacong/ReconBoost) \| [\[Project\]](https://github.com/huacong/ReconBoost)

- This paper explores a novel multi-modal **alternating** learning paradigm pursuing a reconciliation between the exploitation of uni-modal features and the exploration of cross-modal interactions.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TNNLS 2023</div><img src='images/HSR.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**<font size=4>Hierarchical Set-to-set Representation for 3D Cross-modal Retrieval</font>**

Yu Jiang, **Cong Hua**, Yifan Feng, Yue Gao<sup>\*</sup>. (Student first author)

IEEE Transactions on Neural Networks and Learning Systems (**IEEE TNNLS**) 2023

[\[Paper\]](https://ieeexplore.ieee.org/document/10316653) \|[\[Code\]](https://github.com/huacong/HSR) \| [\[Project\]](https://github.com/huacong/HSR)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">SHREC'22</div><img src='images/3DOS.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**<font size=4>SHREC'22 Track: Open-Set 3D Object Retrieval</font>**

$28$ authors including **Cong Hua**. Computers  Graphics 2022

[\[Paper\]](https://doi.org/10.1016/j.cag.2022.07.020) \|[\[Track\]](https://www.moon-lab.tech/shrec22) 


- This paper reports the results of the SHRECâ€™22 track: Open-Set 3D Object Retrieval, the goal of which is to evaluate the performance of different retrieval algorithms under the Open-Set setting and modality-missing setting, respectively. 
</div>
</div>


# ğŸ“– Academic Services
 - *NeruIPS*ï¼šPC Member (2024)

<!-- # ğŸ’¬ Invited Talks & Presentations
- *2024.01*: &nbsp; TechBeat Talk of NeurIPS 2023. [\[Video\]](https://www.techbeat.net/talk-info?id=846).
- *2023.12*: &nbsp; AI TIME Talk of NeurIPS 2023. [\[Page\]](https://mp.weixin.qq.com/s/ur6aB8ojkmlhgtW-bIxLXw).
- *2023.12*: &nbsp; Young Scientists Conference of CSIG. [\[Poster\]](https://github.com/wang22ti/OpenAUC/blob/main/CSIG%20youth%20poster%20-%20OpenAUC.jpg).
- *2023.10*: &nbsp; PhD. student Forum of PRCV 2023. [\[Page\]](https://mp.weixin.qq.com/s/2mSlWBu7NYo88SjFD8Wn8Q).
- *2023.02*: &nbsp; AI TIME Youth PhD Talk of NeurIPS 2022. [\[Video\]](https://www.bilibili.com/video/BV1624y1G7un/?spm_id_from=333.999.0.0&vd_source=356f7336a633368638ff41a90a11197b). -->

# ğŸ– Honors and Awards
- *2023* Excellent graduate thesis of Jilin University. (å‰æ—å¤§å­¦ä¼˜ç§€æ¯•ä¸šè®ºæ–‡)
- *2023* Excellent graduate of Jilin University. (å‰æ—å¤§å­¦ä¼˜ç§€æ¯•ä¸šç”Ÿ) 

# ğŸ“ Educations

<div class='school-box'>
<div><img src='images/ucas.jpg' alt="sym" width="80"></div>
<div class='school-box-text' markdown="1">
2023.09 - now, Ph.D. Student.

Institute of Computing Technology, Chinese Academy of Sciences.

University of Chinese Academy of Sciences, Beijing.
</div>
</div>

<div class='school-box'>
<div><img src='images/JLU.png' alt="sym" width="80"></div>
<div class='school-box-text' markdown="1">
2019.09 - 2023.06, Undergraduate.

School of Computer Science and Technology.

Jilin University, Changchun, Jilin.
</div>
</div>

<div class='school-box'>
<div><img src='images/UA.png' alt="sym" width="80"></div>
<div class='school-box-text' markdown="1">
2022.11 - 2023.02, Research internship funded by the China Scholarship Council.

Department of Radiology & Diagnostic Imaging in the Faculty of Medicine & Dentistry.

University of Alberta, Edmonton, Alberta, Canada.
</div>
</div>


<!-- # ğŸ’» Project

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">XCurve</div><img src='images/Xcurve.png' alt="sym" width="120%"></div></div>
<div class='paper-box-text' markdown="1">

*2020.02 - now*: &nbsp; **<font color='red'> As a core member, </font>** I participated in the development of [XCurve: Machine Learning with X-Curve Metrics](https://github.com/statusrank/XCurve). 

- XCurve focuses on **the design criteria of the objective function for ML tasks**, which can be formulated as a series of X-metric (say AUROC, AUPRC, AUTKC) optimization problems considering the **average performance of all decision thresholds** during the training phase. Welcome to try now and give us feedback!
</div>
</div> -->
